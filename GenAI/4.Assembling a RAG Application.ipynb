{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a508d2c5-84e2-4e5e-badd-a6faf1721bd3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n",
    "  <img\n",
    "    src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\"\n",
    "    alt=\"Databricks Learning\"\n",
    "  >\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc86372b-56aa-44a5-a392-3c2540063bab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# LAB - Assembling a RAG Application\n",
    "\n",
    "In this lab, we will assemble a Retrieval-augmented Generation (RAG) application using the components we previously created. The primary goal is to create a seamless pipeline where users can ask questions, and our system retrieves relevant documents from a Vector Search index to generate informative responses.\n",
    "\n",
    "\n",
    "**Lab Outline:**\n",
    "\n",
    "In this lab, you will need to complete the following tasks;\n",
    "\n",
    "* **Task 1 :** Setup the Retriever Component\n",
    "\n",
    "* **Task 2 :** Setup the Foundation Model\n",
    "\n",
    "* **Task 3 :** Assemble the Complete RAG Solution\n",
    "\n",
    "* **Task 4 :** Save the Model to Model Registry in Unity Catalog\n",
    "\n",
    "**\uD83D\uDCDD Your task:** Complete the **`<FILL_IN>`** sections in the code blocks and follow the other steps as instructed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "85a07c68-a05d-4e61-aa32-6944b361a661",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## REQUIRED - SELECT CLASSIC COMPUTE\n",
    "Before executing cells in this notebook, please select your classic compute cluster in the lab. Be aware that **Serverless** is enabled by default.\n",
    "\n",
    "Follow these steps to select the classic compute cluster:\n",
    "1. Navigate to the top-right of this notebook and click the drop-down menu to select your cluster. By default, the notebook will use **Serverless**.\n",
    "\n",
    "2. If your cluster is available, select it and continue to the next cell. If the cluster is not shown:\n",
    "\n",
    "   - Click **More** in the drop-down.\n",
    "   \n",
    "   - In the **Attach to an existing compute resource** window, use the first drop-down to select your unique cluster.\n",
    "\n",
    "**NOTE:** If your cluster has terminated, you might need to restart it in order to select it. To do this:\n",
    "\n",
    "1. Right-click on **Compute** in the left navigation pane and select *Open in new tab*.\n",
    "\n",
    "2. Find the triangle icon to the right of your compute cluster name and click it.\n",
    "\n",
    "3. Wait a few minutes for the cluster to start.\n",
    "\n",
    "4. Once the cluster is running, complete the steps above to select your cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce9b045b-6c9b-43a2-99d2-f4625862be56",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Requirements\n",
    "\n",
    "Please review the following requirements before starting the lesson:\n",
    "\n",
    "* To run this notebook, you need to use one of the following Databricks runtime(s): **17.3.x-cpu-ml-scala2.13**\n",
    "\n",
    "**\uD83D\uDEA8 Important:** This lab relies on the resources established in the previous one. Please ensure you have completed the prior lab before starting this one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bca24431-eb6c-44d5-aec1-e45131357936",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Classroom Setup\n",
    "\n",
    "Before starting the lab, run the provided classroom setup script. This script will define configuration variables necessary for the lab. Execute the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0bd3b630-339f-47e1-93d9-9e2a51837227",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install -U -qqq databricks-sdk databricks-vectorsearch 'mlflow-skinny[databricks]==3.4.0' langchain==0.3.26 databricks-langchain==0.8.0 PyPDF2==3.0.0 flashrank\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2a298366-352d-45a5-8302-148029313e18",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nThe examples and models presented in this course are intended solely for demonstration and educational purposes.\n Please note that the models and prompt examples may sometimes contain offensive, inaccurate, biased, or harmful content.\n"
     ]
    }
   ],
   "source": [
    "%run ../Includes/Classroom-Setup-04"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "670cc5fc-5d87-41eb-88ce-733782009ecd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Other Conventions:**\n",
    "\n",
    "Throughout this demo, we'll refer to the object `DA`. This object, provided by Databricks Academy, contains variables such as your username, catalog name, schema name, working directory, and dataset locations. Run the code block below to view these details:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "085c0868-08de-46ad-8d76-ecf60306dc9a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Username:          labuser12209929_1761968096@vocareum.com\nCatalog Name:      dbacademy\nSchema Name:       labuser12209929_1761968096\nWorking Directory: /Volumes/dbacademy/ops/labuser12209929_1761968096@vocareum_com\nDataset Location:  NestedNamespace (arxiv='/Volumes/dbacademy_arxiv/v01', dais='/Volumes/dbacademy_dais/v01', news='/Volumes/dbacademy_news/v01', docs='/Volumes/dbacademy_docs/v01')\n"
     ]
    }
   ],
   "source": [
    "print(f\"Username:          {DA.username}\")\n",
    "print(f\"Catalog Name:      {DA.catalog_name}\")\n",
    "print(f\"Schema Name:       {DA.schema_name}\")\n",
    "print(f\"Working Directory: {DA.paths.working_dir}\")\n",
    "print(f\"Dataset Location:  {DA.paths.datasets}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "05cf0fdf-75af-425a-95bf-4e428b04d253",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Task 1: Setup the Retriever Component\n",
    "**Steps:**\n",
    "1. Define the embedding model.\n",
    "1. Get the vector search index that was created in the previous lab.\n",
    "1. Generate a **retriever** from the vector store. The retriever should return **three results.**\n",
    "1. Write a test prompt and show the returned search results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82823fe0-96e6-42f6-b423-ed87a95e6b0d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigned Vector Search endpoint name: vs_endpoint_2.\n"
     ]
    }
   ],
   "source": [
    "## Components we created before\n",
    "vs_endpoint_prefix = \"vs_endpoint_\"\n",
    "vs_endpoint_name = vs_endpoint_prefix+str(get_fixed_integer(DA.unique_name(\"_\")))\n",
    "print(f\"Assigned Vector Search endpoint name: {vs_endpoint_name}.\")\n",
    "\n",
    "vs_index_fullname = f\"{DA.catalog_name}.{DA.schema_name}.lab_pdf_text_managed_vs_index\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ca75ecd9-5e52-4fc3-99c8-9d4832ee7d5c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1761970140.406406    5386 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1761970140.412237    5386 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1761970140.426807    5386 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1761970140.426824    5386 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1761970140.426853    5386 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1761970140.426855    5386 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-11-01 04:09:02,847] [WARNING] [real_accelerator.py:194:get_accelerator] Setting accelerator to CPU. If you have GPU or other accelerator, we were unable to detect it.\n[2025-11-01 04:09:02,851] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cpu (auto detect)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/bin/ld: cannot find -laio: No such file or directory\ncollect2: error: ld returned 1 exit status\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NOTICE] Using a notebook authentication token. Recommended for development only. For improved performance, please use Service Principal based authentication. To disable this message, pass disable_notice=True.\nRelevant documents: [Document(metadata={'source': 'dbfs:/Volumes/dbacademy_arxiv/v01/arxiv-articles/2303.10130.pdf'}, page_content='(Autoretal.,2022a)findsas\\nwell that automation and augmentation exposures tend to be positively correlated. There is also a growing set\\nof studies examining specific economic impacts and opportunities for LLMs (Bommasani et al., 2021; Felten\\net al., 2023; Korinek, 2023; Mollick and Mollick, 2022; Noy and Zhang, 2023; Peng et al., 2023). Alongside\\nthis work, our measurements help characterize the broader potential relevance of language models to the\\nlabor market.\\nGeneral-purpose technologies (e.g. printing, the steam engine) are characterized by widespread prolifera-\\ntion, continuous improvement, and the generation of complementary innovations (Bresnahan and Trajtenberg,\\n1995; Lipsey et al., 2005). Their far-reaching consequences, which unfold over decades, are difficult to\\nanticipate,particularlyinrelationtolabordemand(Bessen,2018;KorinekandStiglitz,2018;Acemogluetal.,\\nWORKING PAPER\\n2020; Benzell et al., 2021). The realization of general purpose technologies’ full potential requires extensive\\nco-invention(BresnahanandTrajtenberg,1995;Bresnahanetal.,1996,2002;Lipseyetal.,2005;Dixonetal.,\\n2021),acostlyandtime-consumingprocessinvolvingthediscoveryofnewbusinessprocedures(David,1990;\\nBresnahan, 1999; Frey, 2019; Brynjolfsson et al., 2021; Feigenbaum and Gross, 2021).'), Document(metadata={'source': 'dbfs:/Volumes/dbacademy_arxiv/v01/arxiv-articles/2303.10130.pdf'}, page_content='Collectively, these characteristics imply that Generative Pre-trained Transformers (GPTs) are general-purpose\\ntechnologies (GPTs). 4(Bresnahan and Trajtenberg, 1995; Lipsey et al., 2005).\\n(Goldfarb et al., 2023) argue that machine learning as a broad category is likely a general-purpose\\ntechnology. Ourevidencesupportsawiderimpact,asevensubsetsofmachinelearningsoftwaremeetthe\\ncriteriaforgeneral-purposetechnologystatusindependently. Thispaper’sprimarycontributionsaretoprovide\\nasetofmeasurementsofLLMimpactpotentialandtodemonstratetheusecaseofapplyingLLMstodevelop\\nsuchmeasurementsefficientlyandatscale. Additionally,weshowcasethegeneral-purposepotentialofLLMs.\\nIf \"GPTs are GPTs,\" the eventual trajectory of LLM development and application may be challenging for\\n3Baumol’s cost disease is a theory that explains why the cost of labor-intensive services, such as healthcare and education,\\nincreases over time. This happens because wages for skilled workers in other industries increase, but there is no corresponding\\nincreaseinproductivityorefficiencyintheseserviceindustries. Therefore,thecostoflaborintheseindustriesbecomesrelatively\\nmore expensive compared to other goods and services in the economy.\\n4For the remainder of the paper we spell out general-purpose technologies when it is used outside of stating \"GPTs are GPTs.\"\\nWORKING PAPER\\npolicymakers to predict and regulate. As with other general-purpose technologies, much of these algorithms’\\npotential will emerge across a broad range of economically valuable use cases, including the creation of new\\ntypesofwork(AcemogluandRestrepo,2018;Autoretal.,2022a).')]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/databricks.mlflow.trace": "\"tr-e2da98babdb53d7bddd25d631ada8729\"",
      "text/plain": [
       "Trace(trace_id=tr-e2da98babdb53d7bddd25d631ada8729)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from databricks.vector_search.client import VectorSearchClient\n",
    "from databricks_langchain import DatabricksEmbeddings\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain.docstore.document import Document\n",
    "from flashrank import Ranker, RerankRequest\n",
    "\n",
    "def get_retriever(cache_dir=f\"{DA.paths.working_dir}/opt\"):\n",
    "\n",
    "    def retrieve(query, k: int=10):\n",
    "        if isinstance(query, dict):\n",
    "            query = next(iter(query.values()))\n",
    "\n",
    "        ## get the vector search index\n",
    "        vsc = VectorSearchClient(disable_notice=True)\n",
    "        vs_index = vsc.get_index(endpoint_name=vs_endpoint_name, index_name=vs_index_fullname)\n",
    "        \n",
    "        # get the query vector\n",
    "        embeddings = DatabricksEmbeddings(endpoint=\"databricks-gte-large-en\")\n",
    "        query_vector = embeddings.embed_query(query)\n",
    "\n",
    "        ## get similar k documents\n",
    "        return query, vs_index.similarity_search(\n",
    "            query_vector=query_vector,\n",
    "            columns=[\"pdf_name\", \"content\"],\n",
    "            num_results=k)\n",
    "\n",
    "    def rerank(query, retrieved, cache_dir, k: int=2):\n",
    "        ## format result to align with reranker lib format \n",
    "        passages = []\n",
    "        for doc in retrieved.get(\"result\", {}).get(\"data_array\", []):\n",
    "            new_doc = {\"file\": doc[0], \"text\": doc[1]}\n",
    "            passages.append(new_doc)       \n",
    "        ## Load the flashrank ranker\n",
    "        ranker = Ranker(model_name=\"rank-T5-flan\", cache_dir=cache_dir)\n",
    "\n",
    "        ## rerank the retrieved documents\n",
    "        rerankrequest = RerankRequest(query=query, passages=passages)\n",
    "        results = ranker.rerank(rerankrequest)[:k]\n",
    "\n",
    "        ## format the results of rerank to be ready for prompt\n",
    "        return [Document(page_content=r.get(\"text\"), metadata={\"source\": r.get(\"file\")}) for r in results]\n",
    "\n",
    "    ## the retriever is a runnable sequence of retrieving and reranking.\n",
    "    return RunnableLambda(retrieve) | RunnableLambda(lambda x: rerank(x[0], x[1], cache_dir))\n",
    "\n",
    "## test our retriever\n",
    "question = {\"input\": \"How does Generative AI impact humans?\"}\n",
    "vectorstore = get_retriever(cache_dir = f\"{DA.paths.working_dir}/opt\")\n",
    "similar_documents = vectorstore.invoke(question)\n",
    "print(f\"Relevant documents: {similar_documents}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32e1d520-da14-48cc-9f6a-3c6ec0edf147",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Task 2: Setup the Foundation Model\n",
    "**Steps:**\n",
    "1. Define the foundation model for generating responses. Use `llama-3.3` as foundation model. \n",
    "2. Test the foundation model to ensure it provides accurate responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "163f0546-e14b-497c-b37b-6bd7d48d6cce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://oregon.cloud.databricks.com/serving-endpoints/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test chat model: content='Generative AI refers to a type of artificial intelligence that is capable of generating new, original content, such as images, videos, music, text, or even entire datasets. This is in contrast to traditional AI, which is typically designed to analyze and process existing data.\\n\\nGenerative AI uses complex algorithms, such as deep learning and neural networks, to learn patterns and structures within existing data. It then uses this knowledge to generate new, synthetic data that is similar in style and structure to the original data. This can be done for a variety of purposes, such as:\\n\\n1. **Content creation**: Generating new images, videos, music, or text that is similar in style to existing content.\\n2. **Data augmentation**: Generating new data to supplement existing datasets, which can be useful for training machine learning models.\\n3. **Style transfer**: Transferring the style of one image or video to another, while preserving the original content.\\n4. **Image synthesis**: Generating new images from scratch, such as generating faces, objects, or scenes.\\n5. **Text generation**: Generating new text, such as articles, stories, or dialogue, that is similar in style to existing text.\\n\\nSome common techniques used in generative AI include:\\n\\n1. **Generative Adversarial Networks (GANs)**: A type of neural network that consists of two models: a generator and a discriminator. The generator creates new data, while the discriminator evaluates the generated data and tells the generator whether it is realistic' additional_kwargs={} response_metadata={'usage': {'prompt_tokens': 16, 'completion_tokens': 300, 'total_tokens': 316}, 'prompt_tokens': 16, 'completion_tokens': 300, 'total_tokens': 316, 'model': 'meta-llama-3.3-70b-instruct-121024', 'model_name': 'meta-llama-3.3-70b-instruct-121024', 'finish_reason': 'length'} id='run--488f306d-a0b4-4e53-b538-567ae52032cb-0'\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/databricks.mlflow.trace": "\"tr-29552315f2d21d43e1510452d2ee9df4\"",
      "text/plain": [
       "Trace(trace_id=tr-29552315f2d21d43e1510452d2ee9df4)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## import necessary libraries\n",
    "from databricks_langchain import ChatDatabricks\n",
    "\n",
    "## define foundation model for generating responses\n",
    "chat_model = ChatDatabricks(endpoint=\"databricks-meta-llama-3-3-70b-instruct\", max_tokens = 300)\n",
    "\n",
    "## test foundation model\n",
    "print(f\"Test chat model: {chat_model.invoke('What is Generative AI?')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "680c78b5-ed49-4bd8-836f-e2160767555a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Task 3: Assemble the Complete RAG Solution\n",
    "**Steps:**\n",
    "1. Merge the retriever and foundation model into a single Langchain chain.\n",
    "2. Configure the Langchain chain with proper templates and context for generating responses.\n",
    "3. Test the complete RAG solution with sample queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b33b503d-ffa9-47dc-bed2-29ab43ec903c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NOTICE] Using a notebook authentication token. Recommended for development only. For improved performance, please use Service Principal based authentication. To disable this message, pass disable_notice=True.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://oregon.cloud.databricks.com/serving-endpoints/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The economic implications of Generative AI (GENAI) are significant and pervasive. According to our analysis, the impacts of Large Language Models (LLMs) like GPT-4 are likely to be widespread and persistent, even if the development of new capabilities is halted. The economic effect of GENAI is expected to increase over time, with potential productivity gains that may not exacerbate cost disease effects.\n\nOur research indicates that the variance explained by previous technology exposure measurements ranges from 60 to 72%, leaving 28 to 40% of the variation in our AI exposure measure unaccounted for. This suggests that GENAI has unique economic implications that are not fully captured by previous technology exposure measurements.\n\nFurthermore, our analysis by industry reveals that information processing industries exhibit high exposure to GENAI, while manufacturing, agriculture, and mining demonstrate lower exposure. This implies that GENAI is likely to have a significant impact on certain sectors, particularly those that rely heavily on information processing.\n\nThe development of complementary technologies is also expected to expand the potential impact of GENAI, making it a general-purpose technology with far-reaching economic implications. Additionally, studies have shown that GENAI can have a positive impact on developer productivity, with evidence from GitHub Copilot suggesting that AI can improve coding efficiency and quality.\n\nOverall, the economic implications of GENAI are complex and multifaceted, with both positive and negative effects on various industries and aspects of the economy. As GENAI continues to evolve and improve, it is essential to closely\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/databricks.mlflow.trace": "\"tr-b3deb05b8df01ecf8f0da531a2b868fa\"",
      "text/plain": [
       "Trace(trace_id=tr-b3deb05b8df01ecf8f0da531a2b868fa)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda, RunnableParallel, RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Prompt template\n",
    "TEMPLATE = \"\"\"You are an assistant for GENAI teaching class. You are answering questions related to Generative AI and how it impacts humans life. If the question is not related to one of these topics, kindly decline to answer. \n",
    "Use the following pieces of context to answer the question at the end:\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Question: {input}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(TEMPLATE)      \n",
    "\n",
    "# Helper functions\n",
    "def format_docs(docs):\n",
    "    # what the model sees in {context}\n",
    "    return \"\\n\\n\".join(d.page_content for d in docs)\n",
    "\n",
    "def unwrap(payload):\n",
    "    # return both answer and normalized context (dicts) like you wanted\n",
    "    docs = payload[\"docs\"]\n",
    "    return {\n",
    "        \"answer\": payload[\"answer\"],\n",
    "        \"context\": [{\"metadata\": getattr(d, \"metadata\", {}), \"page_content\": getattr(d, \"page_content\", \"\")}\n",
    "                    for d in docs],\n",
    "    }\n",
    "\n",
    "# ---- build the chain ----\n",
    "# Step 1: retrieve docs\n",
    "retrieve = RunnableParallel(input=RunnablePassthrough(), docs=get_retriever())\n",
    "\n",
    "# Step 2: pass formatted context + input to the model\n",
    "rag = retrieve | {\n",
    "    \"input\": itemgetter(\"input\"),\n",
    "    \"context\": RunnableLambda(lambda x: format_docs(x[\"docs\"]))\n",
    "} | prompt | chat_model | StrOutputParser()\n",
    "\n",
    "# Keep docs for postprocessing\n",
    "chain = retrieve | {\n",
    "    \"answer\": ({\"input\": itemgetter(\"input\"), \"context\": RunnableLambda(lambda x: format_docs(x[\"docs\"]))}\n",
    "               | prompt | chat_model | StrOutputParser()),\n",
    "    \"docs\": itemgetter(\"docs\"),\n",
    "} | RunnableLambda(unwrap)\n",
    "\n",
    "# Test the complete RAG solution with sample query\n",
    "question = {\"input\": \"What are the generative AI's economical implications?\"}\n",
    "response = chain.invoke(question)\n",
    "print(response['answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "787f2532-1003-47fd-996a-b0e12c6e2c2a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Task 4: Save the Model to Model Registry in Unity Catalog\n",
    "**Steps:**\n",
    "1. Register the assembled RAG model in the Model Registry with Unity Catalog.\n",
    "2. Ensure that all necessary dependencies and requirements are included.\n",
    "3. Provide an input example and infer the signature for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "960e95e0-5615-43b8-ae29-9bd3af814e87",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\uD83D\uDD17 View Logged Model at: https://dbc-6a912028-eced.cloud.databricks.com/ml/experiments/3613252000274365/models/m-fbd48e8dba464c9f9a6cce1d2a225354?o=1236668491373261\n2025/11/01 04:09:32 INFO mlflow: Attempting to auto-detect Databricks resource dependencies for the current langchain model. Dependency auto-detection is best-effort and may not capture all dependencies of your langchain model, resulting in authorization errors when serving or querying your model. We recommend that you explicitly pass `resources` to mlflow.langchain.log_model() to ensure authorization to dependent resources succeeds when the model is deployed.\n2025/11/01 04:09:33 INFO mlflow.tracking.fluent: Active model is set to the logged model with ID: m-fbd48e8dba464c9f9a6cce1d2a225354\n2025/11/01 04:09:33 INFO mlflow.tracking.fluent: Use `mlflow.set_active_model` to set the active model to a different one if needed.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NOTICE] Using a notebook authentication token. Recommended for development only. For improved performance, please use Service Principal based authentication. To disable this message, pass disable_notice=True.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://oregon.cloud.databricks.com/serving-endpoints/chat/completions \"HTTP/1.1 200 OK\"\nSuccessfully registered model 'dbacademy.labuser12209929_1761968096.rag_app_lab_4'.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57b8c653585440fea70514ffd082cdda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\uD83D\uDD17 Created version '1' of model 'dbacademy.labuser12209929_1761968096.rag_app_lab_4': https://dbc-6a912028-eced.cloud.databricks.com/explore/data/models/dbacademy/labuser12209929_1761968096/rag_app_lab_4/version/1?o=1236668491373261\n"
     ]
    }
   ],
   "source": [
    "## import necessary libraries\n",
    "from mlflow.models import infer_signature\n",
    "import mlflow\n",
    "import langchain\n",
    "\n",
    "## set Model Registry URI to Unity Catalog\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "model_name = f\"{DA.catalog_name}.{DA.schema_name}.rag_app_lab_4\"\n",
    "\n",
    "## register the assembled RAG model in Model Registry with Unity Catalog\n",
    "with mlflow.start_run(run_name=\"rag_app_lab_4\") as run:\n",
    "    signature = infer_signature(question, response)\n",
    "    model_info = mlflow.langchain.log_model(\n",
    "        chain,\n",
    "        loader_fn=get_retriever,\n",
    "        name=\"chain\",\n",
    "        registered_model_name=model_name,\n",
    "        pip_requirements=[\n",
    "            \"mlflow==\" + mlflow.__version__,\n",
    "            \"langchain==\" + langchain.__version__,\n",
    "            \"databricks-vectorsearch\",\n",
    "        ],\n",
    "        input_example=question,\n",
    "        signature=signature\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "25df7b36-0c95-4a1a-881f-a78e37fdf4af",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Clean up Resources\n",
    "\n",
    "This was the final lab. You can delete all resources created in this course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "facaa87d-17a1-438a-a584-66560dd48417",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Conclusion\n",
    "\n",
    "In this lab, you learned how to assemble a Retrieval-augmented Generation (RAG) application using Databricks components. By integrating Vector Search for document retrieval and a foundational model for response generation, you created a powerful tool for answering user queries. This lab provided hands-on experience in building end-to-end AI applications and demonstrated the capabilities of Databricks for natural language processing tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "64191547-5edc-4286-8341-2c18418d591b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "&copy; 2025 Databricks, Inc. All rights reserved. Apache, Apache Spark, Spark, the Spark Logo, Apache Iceberg, Iceberg, and the Apache Iceberg logo are trademarks of the <a href=\"https://www.apache.org/\" target=\"_blank\">Apache Software Foundation</a>.<br/><br/><a href=\"https://databricks.com/privacy-policy\" target=\"_blank\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\" target=\"_blank\">Terms of Use</a> | <a href=\"https://help.databricks.com/\" target=\"_blank\">Support</a>"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "4.LAB Solution - Assembling a RAG Application",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}