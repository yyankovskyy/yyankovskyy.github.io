{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "56d78dcf-e52e-4bcd-9338-95f2846b16c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n",
    "  <img\n",
    "    src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\"\n",
    "    alt=\"Databricks Learning\"\n",
    "  >\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c551f03b-90f7-42cf-961d-0b9b44340477",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# LAB - Create Managed Vector Search Index\n",
    "\n",
    "The objective of this lab is to demonstrate the process of creating a **managed** Vector Search index for retrieval-augmented generation (RAG) applications. This involves configuring Databricks Vector Search to ingest data from a Delta table containing text embeddings and metadata.\n",
    "\n",
    "\n",
    "\n",
    "**Lab Outline:**\n",
    "\n",
    "In this lab, you will need to complete the following tasks;\n",
    "\n",
    "* **Task 1 :** Create a Vector Search endpoint to serve the index.\n",
    "\n",
    "* **Task 2 :** Connect Delta table with Vector Search endpoint\n",
    "\n",
    "* **Task 3 :** Test the Vector Search index\n",
    "\n",
    "* **Task 4 :** Re-rank search results\n",
    "\n",
    "**\uD83D\uDCDD Your task:** Complete the **`<FILL_IN>`** sections in the code blocks and follow the other steps as instructed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "398327f3-ecc9-4cb9-97dc-d377b60635e6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## REQUIRED - SELECT CLASSIC COMPUTE\n",
    "Before executing cells in this notebook, please select your classic compute cluster in the lab. Be aware that **Serverless** is enabled by default.\n",
    "\n",
    "Follow these steps to select the classic compute cluster:\n",
    "1. Navigate to the top-right of this notebook and click the drop-down menu to select your cluster. By default, the notebook will use **Serverless**.\n",
    "\n",
    "2. If your cluster is available, select it and continue to the next cell. If the cluster is not shown:\n",
    "\n",
    "   - Click **More** in the drop-down.\n",
    "   \n",
    "   - In the **Attach to an existing compute resource** window, use the first drop-down to select your unique cluster.\n",
    "\n",
    "**NOTE:** If your cluster has terminated, you might need to restart it in order to select it. To do this:\n",
    "\n",
    "1. Right-click on **Compute** in the left navigation pane and select *Open in new tab*.\n",
    "\n",
    "2. Find the triangle icon to the right of your compute cluster name and click it.\n",
    "\n",
    "3. Wait a few minutes for the cluster to start.\n",
    "\n",
    "4. Once the cluster is running, complete the steps above to select your cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6f8c56a5-e951-4be4-bd49-34856b6bd421",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Requirements\n",
    "\n",
    "Please review the following requirements before starting the lesson:\n",
    "\n",
    "* To run this notebook, you need to use one of the following Databricks runtime(s): **17.3.x-cpu-ml-scala2.13**\n",
    "\n",
    "**\uD83D\uDEA8 Important: This lab relies on the resources created in the previous Lab. Please ensure you have completed the prior lab before starting this lab.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0b289bce-0a2f-496a-95fe-a18e8bd75e80",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Classroom Setup\n",
    "\n",
    "Before starting the lab, run the provided classroom setup script. This script will define configuration variables necessary for the lab. Execute the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "daa77bcc-8131-42f8-a427-7de42e601c9b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nlangchain 0.3.21 requires langchain-core<1.0.0,>=0.3.45, but you have langchain-core 1.0.2 which is incompatible.\nlangchain 0.3.21 requires langsmith<0.4,>=0.1.17, but you have langsmith 0.4.39 which is incompatible.\nlangchain-text-splitters 0.3.8 requires langchain-core<1.0.0,>=0.3.51, but you have langchain-core 1.0.2 which is incompatible.\u001B[0m\u001B[31m\n\u001B[0m\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install -U -qqqq databricks-vectorsearch 'mlflow-skinny[databricks]==3.4.0' PyPDF2==3.0.0 databricks-sdk flashrank \n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a8cb793-30a1-41ac-9f9c-07cf0ee7e946",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nThe examples and models presented in this course are intended solely for demonstration and educational purposes.\n Please note that the models and prompt examples may sometimes contain offensive, inaccurate, biased, or harmful content.\n"
     ]
    }
   ],
   "source": [
    "%run ../Includes/Classroom-Setup-03"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "efeabe9c-bef0-49f0-89e6-fed0fe7c5fbf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Other Conventions:**\n",
    "\n",
    "Throughout this demo, we'll refer to the object `DA`. This object, provided by Databricks Academy, contains variables such as your username, catalog name, schema name, working directory, and dataset locations. Run the code block below to view these details:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eb626a9e-6836-4cb7-a3b0-814c9a5d641e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Username:          labuser12209929_1761968096@vocareum.com\nCatalog Name:      dbacademy\nSchema Name:       labuser12209929_1761968096\nWorking Directory: /Volumes/dbacademy/ops/labuser12209929_1761968096@vocareum_com\nDataset Location:  NestedNamespace (arxiv='/Volumes/dbacademy_arxiv/v01', dais='/Volumes/dbacademy_dais/v01', news='/Volumes/dbacademy_news/v01', docs='/Volumes/dbacademy_docs/v01')\n"
     ]
    }
   ],
   "source": [
    "print(f\"Username:          {DA.username}\")\n",
    "print(f\"Catalog Name:      {DA.catalog_name}\")\n",
    "print(f\"Schema Name:       {DA.schema_name}\")\n",
    "print(f\"Working Directory: {DA.paths.working_dir}\")\n",
    "print(f\"Dataset Location:  {DA.paths.datasets}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af9dd1a2-98fd-4a50-8f29-ed3e49e33434",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Task 1: Create a Vector Search Endpoint\n",
    "\n",
    "To start, you need to create a Vector Search endpoint to serve the index.\n",
    "\n",
    "**\uD83D\uDEA8IMPORTANT: Vector Search endpoints must be created before running the rest of the demo. These are already created for you in Databricks Lab environment. See instructions in the demo notebook if you run this notebook in another environment.**\n",
    "\n",
    "**\uD83D\uDCA1 Instructions:**\n",
    "\n",
    "1. Define the endpoint that you will use if you don't have endpoint creation permissions. \n",
    "1. [Optional]: Create a new endpoint. Check if the vector search endpoint exists, if not, create it.\n",
    "1. Wait for the endpoint to be ready.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd4565c7-58da-44c1-be92-6dec3ae4d468",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Step-by-Step Instructions:\n",
    "\n",
    "\n",
    "**Vector Search Endpoint**: The first step for creating a Vector Search index is to create a compute endpoint. This endpoint is already created in this lab environment.\n",
    "\n",
    "**Wait for Endpoint to be Ready**: After defining the endpoint name, check the status of the endpoint using the provided function `wait_for_vs_endpoint_to_be_ready`.\n",
    "\n",
    "Additionally, you can check the endpoint status in the Databricks workspace [Vector Search Endpoints in Compute section](#/setting/clusters/vector-search)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e859c8de-268a-4981-8436-c30f3404cb65",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigned Vector Search endpoint name: vs_endpoint_2.\n"
     ]
    }
   ],
   "source": [
    "## assign vs search endpoint by username\n",
    "vs_endpoint_prefix = \"vs_endpoint_\"\n",
    "vs_endpoint_name = vs_endpoint_prefix + str(get_fixed_integer(DA.unique_name(\"_\")))\n",
    "print(f\"Assigned Vector Search endpoint name: {vs_endpoint_name}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d301152-a30c-4760-9bcf-79cf892634a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint named vs_endpoint_2 is ready.\n"
     ]
    }
   ],
   "source": [
    "import databricks.sdk.service.catalog as c\n",
    "from databricks.vector_search.client import VectorSearchClient\n",
    "from databricks.sdk import WorkspaceClient\n",
    "\n",
    "vsc = VectorSearchClient(disable_notice=True)\n",
    "\n",
    "## check the status of the endpoint.\n",
    "wait_for_vs_endpoint_to_be_ready(vsc, vs_endpoint_name)\n",
    "print(f\"Endpoint named {vs_endpoint_name} is ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d8d038d-5706-4a06-903b-3b575a551586",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Task 2: Create a Managed Vector Search Index\n",
    "\n",
    "Now, connect the Delta table containing text and metadata with the Vector Search endpoint. In this lab, you will create a **managed** index, which means you don't need to create the embeddings manually. For API details, check the [documentation page](https://docs.databricks.com/en/generative-ai/create-query-vector-search.html#create-index-using-the-python-sdk).\n",
    "\n",
    "\n",
    "**\uD83D\uDCCC Note 1: You will use the embeddings table that you created in the previous lab. If you haven't completed that lab, stop here and complete it first.**\n",
    "\n",
    "**\uD83D\uDCCC Note 2:** Although the source table already has the embedding column precomputed, we are not going to use it here to test the managed vector search capability to populate embeddings on the fly during data ingestion and query.\n",
    "\n",
    "**\uD83D\uDCA1 Instructions:**\n",
    "\n",
    "1. Define the source Delta table containing the text to be indexed.\n",
    "\n",
    "1. Create a Vector Search index. Use these parameters; source column as `content` and `databricks-gte-large-en` as embedding model. Also, the sync process should be  `manually triggered`.\n",
    "\n",
    "1. Create or synchronize the Vector Search index based on the source Delta table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc2392c0-6bc8-47f2-82ac-6bd616dc03ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating index dbacademy.labuser12209929_1761968096.lab_pdf_text_managed_vs_index on endpoint vs_endpoint_2...\nWaiting for index to be ready, this can take a few min... {'detailed_state': 'PROVISIONING_INDEX', 'message': 'Delta sync Index creation is pending. Check latest status: https://dbc-6a912028-eced.cloud.databricks.com/explore/data/dbacademy/labuser12209929_1761968096/lab_pdf_text_managed_vs_index', 'indexed_row_count': 0, 'ready': False, 'index_url': 'dbc-6a912028-eced.cloud.databricks.com/api/2.0/vector-search/indexes/dbacademy.labuser12209929_1761968096.lab_pdf_text_managed_vs_index'} - pipeline url:dbc-6a912028-eced.cloud.databricks.com/api/2.0/vector-search/indexes/dbacademy.labuser12209929_1761968096.lab_pdf_text_managed_vs_index\n"
     ]
    }
   ],
   "source": [
    "## the Delta table containing the text embeddings and metadata.\n",
    "source_table_fullname = f\"{DA.catalog_name}.{DA.schema_name}.lab_pdf_text_embeddings\"\n",
    "\n",
    "## the Delta table to store the Vector Search index.\n",
    "vs_index_fullname = f\"{DA.catalog_name}.{DA.schema_name}.lab_pdf_text_managed_vs_index\"\n",
    "\n",
    "## create or sync the index.\n",
    "if not index_exists(vsc, vs_endpoint_name, vs_index_fullname):\n",
    "  print(f\"Creating index {vs_index_fullname} on endpoint {vs_endpoint_name}...\")\n",
    "  \n",
    "  vsc.create_delta_sync_index(\n",
    "    endpoint_name=vs_endpoint_name,\n",
    "    index_name=vs_index_fullname,\n",
    "    source_table_name=source_table_fullname,\n",
    "    pipeline_type=\"TRIGGERED\",\n",
    "    primary_key=\"id\",\n",
    "    embedding_source_column=\"content\",\n",
    "    embedding_model_endpoint_name=\"databricks-gte-large-en\"\n",
    "  )\n",
    "else:\n",
    "  ## trigger a sync to update our vs content with the new data saved in the table.\n",
    "  vsc.get_index(vs_endpoint_name, vs_index_fullname).sync()\n",
    "\n",
    "## let's wait for the index to be ready and all our embeddings to be created and indexed.\n",
    "wait_for_index_to_be_ready(vsc, vs_endpoint_name, vs_index_fullname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d06b6eb-b9c2-4293-a6e9-7b953b161762",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Task 3: Search Documents Similar to the Query\n",
    "\n",
    "Test the Vector Search index by searching for similar content based on a sample query.\n",
    "\n",
    "**\uD83D\uDCA1 Instructions:**\n",
    "\n",
    "1. Get the index instance that we created.\n",
    "\n",
    "1. Send a sample query to the language model endpoint using **query text**. \uD83D\uDEA8 Note: As you created a managed index, you will use plain text for similarity search using `query_text` parameter.\n",
    "\n",
    "1. Use the embeddings to search for similar content in the Vector Search index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91a4f5fb-7aca-44f6-866c-7566e9f37640",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NOTICE] Using a notebook authentication token. Recommended for development only. For improved performance, please use Service Principal based authentication. To disable this message, pass disable_notice=True.\n[['dbfs:/Volumes/dbacademy_arxiv/v01/arxiv-articles/2302.09419.pdf',\n  'Some defense approaches have been pro-\\n'\n  'posed to defend against such attacks. [268] designs an auxiliary anomaly detection classiﬁer '\n  'and uses a\\n'\n  'multi-task learning procedure to defend against adversarial samples. On the other hand, some '\n  'defects in the\\n'\n  'PFM may be inherited by the custom models in transfer learning, such as the adversarial '\n  'vulnerabilities and\\n'\n  'backdoors mentioned above. To mitigate this issue, [269] proposes a relevant model slicing '\n  'technique to\\n'\n  'reduce defect inheritance during transfer learning while retaining useful knowledge from the '\n  'PFM.\\n'\n  'Data Privacy in PFMs LLMs and other PFMs have been trained on private datasets [270]. The re-\\n'\n  'searchers have discovered that by querying the massive LMs, it is feasible to recover speciﬁc '\n  'training sam-\\n'\n  'ples. An adversary may, for instance, obtain IRC discussions and personally identiﬁable '\n  'information. Even\\n'\n  'worse, because large models have so many parameters, it is simple for PFM to memorize or learn '\n  'private\\n'\n  'information, making larger models more prone to attack than smaller ones. Many PFMs such as the '\n  'LLMs\\n'\n  'have been trained on private datasets. The researchers have found that it is possible to '\n  'recover individual\\n'\n  'training examples by querying the LLMs. For instance, an adversary can extract examples '\n  'including per-\\n'\n  'sonally identiﬁable information, and Internet Relay Chat (IRC) conversations. Even worse, '\n  'because of the\\n'\n  'billion parameters of large models, it is easy for PFM to learn private information, making the '\n  'larger model\\n'\n  'more vulnerable than smaller models. We must take privacy-preserving measures into account '\n  'during all\\n'\n  'PFM processes, including data processing, model training, model inference, and system '\n  'deployment, in\\n'\n  'order to reduce the risks of privacy leakage.\\n'\n  '8 Future Research Challenges and Open Problems\\n'\n  'The PFM can avoid training models from the scratch, which is a breakthrough from weak AI to '\n  'general AI.',\n  0.0028242578],\n ['dbfs:/Volumes/dbacademy_arxiv/v01/arxiv-articles/2302.09419.pdf',\n  'Knowledge distillation refers to the transfer of knowledge from the larger teacher model to the '\n  'smaller\\n'\n  'student model through the use of a soft label, etc. DistilBERT [261], for example, uses the '\n  'knowledge dis-\\n'\n  'tillation method to compress BERT, reducing the size of the BERT model by 40% while retaining '\n  '97% of\\n'\n  'its language comprehension.\\n'\n  '7.3 Security and Privacy\\n'\n  'The security risks, social bias, and data privacy in PFMs become an important research topic. '\n  'Qiu et al. [5]\\n'\n  'recognize that deep neural networks can be attacked by adversarial samples, which mislead the '\n  'model to\\n'\n  'produce false predictions. Due to the excellent portability of pretraining models, they have '\n  'been widely used\\n'\n  'in NLP, CV , and GL. However, it has been found that the pretraining model is susceptible to '\n  'the inﬂuence of\\n'\n  'adversarial samples. A tiny interference of the original input may mislead the pretraining '\n  'model to produce\\n'\n  'speciﬁc false predictions. Meanwhile, it is possible to recover the data samples by querying '\n  'the PFMs which\\n'\n  'can cause privacy leakage.\\n'\n  'Generation Adversarial Samples The adversarial sample originates from the image. The '\n  'adversarial\\n'\n  'samples of the image are hard to recognize with an invisible change. For example, only one '\n  'pixel of the\\n'\n  'image is modiﬁed. Human beings do not easily detect such disturbance, but the neural network '\n  'can identify\\n'\n  'the modiﬁed image, which is the original purpose of the adversarial sample. Some work has found '\n  'that pre-\\n'\n  'trained LMs are vulnerable in some scenarios. Jin et al. [262] successfully attack the three '\n  'target models of\\n'\n  'BERT, CNN, and RNN by generating natural adversarial samples, which indicates that the current '\n  'language\\n'\n  'processing model still has a large room for improvement in terms of security. However, it is '\n  'difﬁcult to\\n'\n  'achieve due to the distinct discreteness of languages in NLP.',\n  0.002664712],\n ['dbfs:/Volumes/dbacademy_arxiv/v01/arxiv-articles/2311.15732.pdf',\n  'or instance, the DTD dataset’s\\n'\n  'top-1 accuracy soared to 98% with original filenames but\\n'\n  'normalized to 57% when filenames were anonymized. To\\n'\n  'address this, we hashed sample names to ensure GPT-4V\\n'\n  'focuses on visuals over filename cues.\\n'\n  'Safety system in GPT-4V . Throughout our dataset evalua-\\n'\n  '8\\n'\n  'tions, we stumbled upon specific instances, as depicted in\\n'\n  'Figure 9, where GPT-4V refused to generate predictions,\\n'\n  'stating: “ Your input image may contain content that is not\\n'\n  'allowed by our safety system. ” We surmise that this pre-\\n'\n  'cautionary mechanism is designed to ensure that GPT-4V\\n'\n  'adheres to ethical guidelines by avoiding engagement with\\n'\n  'potentially sensitive or inappropriate content.\\n'\n  'GPT-4V API Costs. We offer an estimate that using the\\n'\n  'GPT-4V API for one testing round across all datasets costs\\n'\n  'about $4000 for reader’s reference.\\n'\n  '6. Conclusion and Limitation\\n'\n  'This work aims to quantitatively evaluating the linguistic\\n'\n  'and visual capabilities of the current state-of-the-art large\\n'\n  'multimodal model GPT-4 in zero-shot visual recognition\\n'\n  'tasks. To ensure a comprehensive evaluation, we have\\n'\n  'conducted experiments across three modalities—images,\\n'\n  'videos, and point clouds—spanning a total of 16 bench-\\n'\n  'marks. We hope our empirical study and experience will\\n'\n  'benefit the community, fostering the evolution of future\\n'\n  'multimodal models.\\n'\n  'Limitations: 1) This study has focused solely on funda-\\n'\n  'mental visual recognition tasks. A comprehensive quanti-\\n'\n  'tative analysis of other tasks, such as object detection, is\\n'\n  'necessary to truly gauge the breadth of these models’ ca-\\n'\n  'pabilities in analyzing complex visual information. 2) This\\n'\n  'work is limited to the evaluation of GPT-4 alone.',\n  0.0023497415],\n ['dbfs:/Volumes/dbacademy_arxiv/v01/arxiv-articles/2302.09419.pdf',\n  'The models cannot reach a better level of stability and match different downstream\\n'\n  'tasks. This means that the model cannot serve the real purpose of human language use.\\n'\n  '8.3 Challenges on Model Design\\n'\n  'Most existing structures of PFMs are tried for text, image, and graph. The primary method is to '\n  'increase\\n'\n  'data, improve computation power, and design training procedures to achieve better results. How '\n  'to make a\\n'\n  'trade-off between data, computing resources, and predictive performance is worth studying.\\n'\n  'Model Variety There are many attempts at model design, such as generation-based models in the '\n  'CV\\n'\n  'area. However, GAN-based approaches are not popular for the following two reasons: 1) the '\n  'discriminator\\n'\n  'has learned meaningful feature representations, but they are forgotten during training [273]; '\n  '2) the mode\\n'\n  'collapse causes the generator to output samples in singular mode to cheat the discriminator. As '\n  'a result,\\n'\n  'although researchers attempt to apply GAN-based approaches on SSL for pretraining, the '\n  'difﬁculties in the\\n'\n  'convergence of discriminator and divergence of generator hinder development and progress in '\n  'this area.\\n'\n  'Model Compression With the wide application of the Transformer and the pretraining model '\n  'showing a\\n'\n  'general trend of growth, the computational complexity of the pretraining model has become the '\n  'focus of\\n'\n  'attention. Due to the huge hardware requirements of model training and other reasons, the high '\n  'threshold\\n'\n  'makes it difﬁcult for researchers to train from scratch. BERT-base and GPT-3 contain about 108 '\n  'million\\n'\n  'parameters and 175 billion parameters, respectively. It is not conducive to the development of '\n  'relevant\\n'\n  'research work. There are some works for pretraining model compression, such as ALBERT having '\n  'fewer\\n'\n  'parameters and better effect than BERT-base. The improvement models still require powerful '\n  'computing\\n'\n  'equipment, making them difﬁcult to apply universally. Reducing the high computing cost is one '\n  'of the main\\n'\n  'challenges in future research.',\n  0.0022753063]]\n"
     ]
    }
   ],
   "source": [
    "## get VS index\n",
    "index = vsc.get_index(vs_endpoint_name, vs_index_fullname)\n",
    "\n",
    "question = \"What are the security and privacy concerns when training generative models?\"\n",
    "\n",
    "## search for similar documents  \n",
    "results = index.similarity_search(\n",
    "    query_text = question,\n",
    "    columns=[\"pdf_name\", \"content\"],\n",
    "    num_results=4\n",
    "    )\n",
    "\n",
    "## show the results\n",
    "docs = results.get(\"result\", {}).get(\"data_array\", [])\n",
    "\n",
    "pprint(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b2b309a-2281-401c-bf4e-2d68ddf837e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Task 4: Re-rank Search Results\n",
    "\n",
    "You have retrieved some documents that are similar to the query text. However, the question of which documents are the most relevant is not done by the vector search results. Use `flashrank` library to re-rank the results and show the most relevant top 3 documents. \n",
    "\n",
    "**\uD83D\uDCA1 Instructions:**\n",
    "\n",
    "1. Define `flashrank` with **`rank-T5-flan`** model.\n",
    "\n",
    "1. Re-rank the search results.\n",
    "\n",
    "1. Show the most relevant **top 3** documents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b2b0810-0568-4293-b477-dc9e0440690d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flashrank.Ranker:Downloading rank-T5-flan...\n\rrank-T5-flan.zip:   0%|          | 0.00/73.7M [00:00<?, ?iB/s]\rrank-T5-flan.zip:   3%|▎         | 2.55M/73.7M [00:00<00:02, 26.7MiB/s]\rrank-T5-flan.zip:   7%|▋         | 5.09M/73.7M [00:00<00:03, 21.9MiB/s]\rrank-T5-flan.zip:  11%|█         | 8.03M/73.7M [00:00<00:02, 25.5MiB/s]\rrank-T5-flan.zip:  15%|█▍        | 10.8M/73.7M [00:00<00:02, 26.7MiB/s]\rrank-T5-flan.zip:  19%|█▉        | 14.1M/73.7M [00:00<00:02, 29.4MiB/s]\rrank-T5-flan.zip:  23%|██▎       | 17.3M/73.7M [00:00<00:01, 30.8MiB/s]\rrank-T5-flan.zip:  28%|██▊       | 20.5M/73.7M [00:00<00:01, 31.7MiB/s]\rrank-T5-flan.zip:  32%|███▏      | 23.6M/73.7M [00:00<00:01, 31.8MiB/s]\rrank-T5-flan.zip:  36%|███▌      | 26.6M/73.7M [00:00<00:01, 31.6MiB/s]\rrank-T5-flan.zip:  41%|████      | 30.0M/73.7M [00:01<00:01, 32.7MiB/s]\rrank-T5-flan.zip:  45%|████▍     | 33.1M/73.7M [00:01<00:01, 31.0MiB/s]\rrank-T5-flan.zip:  49%|████▉     | 36.1M/73.7M [00:01<00:01, 30.2MiB/s]\rrank-T5-flan.zip:  53%|█████▎    | 39.0M/73.7M [00:01<00:01, 29.6MiB/s]\rrank-T5-flan.zip:  57%|█████▋    | 41.8M/73.7M [00:01<00:01, 28.3MiB/s]\rrank-T5-flan.zip:  61%|██████    | 44.7M/73.7M [00:01<00:01, 28.8MiB/s]\rrank-T5-flan.zip:  66%|██████▌   | 48.6M/73.7M [00:01<00:00, 32.4MiB/s]\rrank-T5-flan.zip:  73%|███████▎  | 53.5M/73.7M [00:01<00:00, 37.7MiB/s]\rrank-T5-flan.zip:  78%|███████▊  | 57.8M/73.7M [00:01<00:00, 39.7MiB/s]\rrank-T5-flan.zip:  84%|████████▎ | 61.6M/73.7M [00:02<00:00, 33.9MiB/s]\rrank-T5-flan.zip:  90%|████████▉ | 66.0M/73.7M [00:02<00:00, 37.3MiB/s]\rrank-T5-flan.zip:  97%|█████████▋| 71.1M/73.7M [00:02<00:00, 41.8MiB/s]\rrank-T5-flan.zip: 100%|██████████| 73.7M/73.7M [00:02<00:00, 33.1MiB/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'file': 'dbfs:/Volumes/dbacademy_arxiv/v01/arxiv-articles/2302.09419.pdf', 'text': 'Knowledge distillation refers to the transfer of knowledge from the larger teacher model to the smaller\\nstudent model through the use of a soft label, etc. DistilBERT [261], for example, uses the knowledge dis-\\ntillation method to compress BERT, reducing the size of the BERT model by 40% while retaining 97% of\\nits language comprehension.\\n7.3 Security and Privacy\\nThe security risks, social bias, and data privacy in PFMs become an important research topic. Qiu et al. [5]\\nrecognize that deep neural networks can be attacked by adversarial samples, which mislead the model to\\nproduce false predictions. Due to the excellent portability of pretraining models, they have been widely used\\nin NLP, CV , and GL. However, it has been found that the pretraining model is susceptible to the inﬂuence of\\nadversarial samples. A tiny interference of the original input may mislead the pretraining model to produce\\nspeciﬁc false predictions. Meanwhile, it is possible to recover the data samples by querying the PFMs which\\ncan cause privacy leakage.\\nGeneration Adversarial Samples The adversarial sample originates from the image. The adversarial\\nsamples of the image are hard to recognize with an invisible change. For example, only one pixel of the\\nimage is modiﬁed. Human beings do not easily detect such disturbance, but the neural network can identify\\nthe modiﬁed image, which is the original purpose of the adversarial sample. Some work has found that pre-\\ntrained LMs are vulnerable in some scenarios. Jin et al. [262] successfully attack the three target models of\\nBERT, CNN, and RNN by generating natural adversarial samples, which indicates that the current language\\nprocessing model still has a large room for improvement in terms of security. However, it is difﬁcult to\\nachieve due to the distinct discreteness of languages in NLP.', 'score': np.float32(0.6079372)}\n\n{'file': 'dbfs:/Volumes/dbacademy_arxiv/v01/arxiv-articles/2302.09419.pdf', 'text': 'The models cannot reach a better level of stability and match different downstream\\ntasks. This means that the model cannot serve the real purpose of human language use.\\n8.3 Challenges on Model Design\\nMost existing structures of PFMs are tried for text, image, and graph. The primary method is to increase\\ndata, improve computation power, and design training procedures to achieve better results. How to make a\\ntrade-off between data, computing resources, and predictive performance is worth studying.\\nModel Variety There are many attempts at model design, such as generation-based models in the CV\\narea. However, GAN-based approaches are not popular for the following two reasons: 1) the discriminator\\nhas learned meaningful feature representations, but they are forgotten during training [273]; 2) the mode\\ncollapse causes the generator to output samples in singular mode to cheat the discriminator. As a result,\\nalthough researchers attempt to apply GAN-based approaches on SSL for pretraining, the difﬁculties in the\\nconvergence of discriminator and divergence of generator hinder development and progress in this area.\\nModel Compression With the wide application of the Transformer and the pretraining model showing a\\ngeneral trend of growth, the computational complexity of the pretraining model has become the focus of\\nattention. Due to the huge hardware requirements of model training and other reasons, the high threshold\\nmakes it difﬁcult for researchers to train from scratch. BERT-base and GPT-3 contain about 108 million\\nparameters and 175 billion parameters, respectively. It is not conducive to the development of relevant\\nresearch work. There are some works for pretraining model compression, such as ALBERT having fewer\\nparameters and better effect than BERT-base. The improvement models still require powerful computing\\nequipment, making them difﬁcult to apply universally. Reducing the high computing cost is one of the main\\nchallenges in future research.', 'score': np.float32(0.5752995)}\n\n{'file': 'dbfs:/Volumes/dbacademy_arxiv/v01/arxiv-articles/2302.09419.pdf', 'text': 'Some defense approaches have been pro-\\nposed to defend against such attacks. [268] designs an auxiliary anomaly detection classiﬁer and uses a\\nmulti-task learning procedure to defend against adversarial samples. On the other hand, some defects in the\\nPFM may be inherited by the custom models in transfer learning, such as the adversarial vulnerabilities and\\nbackdoors mentioned above. To mitigate this issue, [269] proposes a relevant model slicing technique to\\nreduce defect inheritance during transfer learning while retaining useful knowledge from the PFM.\\nData Privacy in PFMs LLMs and other PFMs have been trained on private datasets [270]. The re-\\nsearchers have discovered that by querying the massive LMs, it is feasible to recover speciﬁc training sam-\\nples. An adversary may, for instance, obtain IRC discussions and personally identiﬁable information. Even\\nworse, because large models have so many parameters, it is simple for PFM to memorize or learn private\\ninformation, making larger models more prone to attack than smaller ones. Many PFMs such as the LLMs\\nhave been trained on private datasets. The researchers have found that it is possible to recover individual\\ntraining examples by querying the LLMs. For instance, an adversary can extract examples including per-\\nsonally identiﬁable information, and Internet Relay Chat (IRC) conversations. Even worse, because of the\\nbillion parameters of large models, it is easy for PFM to learn private information, making the larger model\\nmore vulnerable than smaller models. We must take privacy-preserving measures into account during all\\nPFM processes, including data processing, model training, model inference, and system deployment, in\\norder to reduce the risks of privacy leakage.\\n8 Future Research Challenges and Open Problems\\nThe PFM can avoid training models from the scratch, which is a breakthrough from weak AI to general AI.', 'score': np.float32(0.5703862)}\n"
     ]
    }
   ],
   "source": [
    "from flashrank import Ranker, RerankRequest\n",
    "\n",
    "## define the ranker.\n",
    "cache_dir = f\"{DA.paths.working_dir}/opt\"\n",
    "\n",
    "ranker = Ranker(model_name=\"rank-T5-flan\", cache_dir=cache_dir)\n",
    "\n",
    "## format the result to align with reranker library format. \n",
    "passages = []\n",
    "for doc in docs:\n",
    "    new_doc = {\"file\": doc[0], \"text\": doc[1]}\n",
    "    passages.append(new_doc)\n",
    "\n",
    "## rerank the passages.\n",
    "rerankrequest = RerankRequest(query=question, passages=passages)\n",
    "ranked_passages = ranker.rerank(rerankrequest)\n",
    "\n",
    "## show the top 3 results.\n",
    "print(*ranked_passages[:3], sep=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "55642a18-fd2a-4ed0-b569-840497f52b97",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Clean up Classroom\n",
    "\n",
    "**\uD83D\uDEA8 Warning:** Please don't delete the catalog and tables created in this lab as next labs depend on these resources. To clean-up the classroom assets, run the classroom clean-up script in the last lab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5766fff2-36f0-44e1-bfe0-5bc86967b43e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Conclusion\n",
    "\n",
    "In this lab, you learned how to set up a Vector Search index using Databricks Vector Search for retrieval-augmented generation (RAG) applications. By following the tasks, you successfully created a Vector Search endpoint, connected a Delta table containing text embeddings, and tested the search functionality. Furthermore, using a re-ranking library, you re-ordered the search results from the most relevant to least relevant documents. This lab provided hands-on experience in configuring and utilizing Vector Search, empowering you to enhance content retrieval and recommendation systems in your projects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "445262e0-5186-434e-a89b-18938162b396",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "&copy; 2025 Databricks, Inc. All rights reserved. Apache, Apache Spark, Spark, the Spark Logo, Apache Iceberg, Iceberg, and the Apache Iceberg logo are trademarks of the <a href=\"https://www.apache.org/\" target=\"_blank\">Apache Software Foundation</a>.<br/><br/><a href=\"https://databricks.com/privacy-policy\" target=\"_blank\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\" target=\"_blank\">Terms of Use</a> | <a href=\"https://help.databricks.com/\" target=\"_blank\">Support</a>"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "3.LAB Solution - Create Managed Vector Search Index",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}